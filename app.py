import streamlit as st
import pandas as pd
import re
from io import BytesIO
from PIL import Image
import os

# =========================
# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
# =========================
st.set_page_config(
    page_title="Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ…",
    page_icon="ğŸ“–",
    layout="wide"
)

# =========================
# ØµÙˆØ±Ø© Ø§Ù„Ø¹Ù†ÙˆØ§Ù†
# =========================
header_img = Image.open("assets/header.png")
st.image(header_img, use_container_width=True)

# =========================
# Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„
# =========================
def remove_tashkeel(text):
    tashkeel = re.compile(
        r'[\u0610-\u061A\u064B-\u065F\u0670\u06D6-\u06DC\u06DF-\u06E8\u06EA-\u06ED]'
    )
    return tashkeel.sub('', str(text))

# =========================
# ØªÙ„ÙˆÙŠÙ† Ø§Ù„ØªØ´ÙƒÙŠÙ„ Ø¨Ø§Ù„Ù„ÙˆÙ† Ø§Ù„Ø°Ù‡Ø¨ÙŠ Bold
# =========================
def highlight_tashkeel(text):
    tashkeel_marks = re.compile(r'([\u0610-\u061A\u064B-\u065F\u0670\u06D6-\u06ED])')
    return tashkeel_marks.sub(r'<span style="color:#CFA500; font-weight:bold;">\1</span>', text)

# =========================
# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø£ØµÙ„ÙŠØ©
# =========================
def extract_original_letters(ayah):
    txt = remove_tashkeel(ayah)
    txt = normalize_hamza_to_alif(txt)
    txt = re.sub(r'[^Ø§-ÙŠ]', '', txt)  # Ø­Ø°Ù ÙƒÙ„ Ø´ÙŠØ¡ ØºÙŠØ± Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
    letters = []
    for c in txt:
        if c not in letters:
            letters.append(c)
    return "".join(letters)

# =========================
# ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù‡Ù…Ø²Ø§Øª Ù„Ù„Ø¨Ø­Ø« Ø§Ù„Ø¬Ø¯ÙŠØ¯
# =========================
def normalize_hamza(text):
    return re.sub(r'[Ø£Ø¥Ø¢Ø¤Ø¦]', 'Ø¡', text)

# =========================
# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø£ØµÙ„ÙŠØ© Ø¨Ø¯ÙˆÙ† ØªÙƒØ±Ø§Ø±
# =========================
def extract_original_letters(ayah):
    txt = remove_tashkeel(ayah)
    txt = normalize_hamza(txt)
    txt = re.sub(r'[^Ø¡Ø§Ø¨ØªØ«Ø¬Ø­Ø®Ø¯Ø°Ø±Ø²Ø³Ø´ØµØ¶Ø·Ø¸Ø¹ØºÙÙ‚ÙƒÙ„Ù…Ù†Ù‡ÙˆÙŠ]', '', txt)
    txt = txt.replace(" ", "")
    letters = []
    for c in txt:
        if c not in letters:
            letters.append(c)
    return "".join(letters)

# =========================
# ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù‡Ù…Ø²Ø§Øª ÙˆØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ "Ø§"
# =========================
def normalize_hamza_to_alif(text):
    return re.sub(r"[Ø£Ø¥Ø¢Ø¤Ø¦Ø¡]", "Ø§", text)
# =========================
# ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù‡Ù…Ø²Ø§Øª Ù„Ù„Ø¨Ø­Ø« Ø§Ù„Ø¬Ø¯ÙŠØ¯
# =========================
def normalize_hamza(text):
    return re.sub(r'[Ø£Ø¥Ø¢Ø¤Ø¦]', 'Ø¡', text)

# =========================
# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø£ØµÙ„ÙŠØ© Ø¨Ø¯ÙˆÙ† ØªÙƒØ±Ø§Ø±
# =========================
def extract_original_letters(ayah):
    txt = remove_tashkeel(ayah)
    txt = normalize_hamza(txt)
    txt = re.sub(r'[^Ø¡Ø§Ø¨ØªØ«Ø¬Ø­Ø®Ø¯Ø°Ø±Ø²Ø³Ø´ØµØ¶Ø·Ø¸Ø¹ØºÙÙ‚ÙƒÙ„Ù…Ù†Ù‡ÙˆÙŠ]', '', txt)
    txt = txt.replace(" ", "")
    letters = []
    for c in txt:
        if c not in letters:
            letters.append(c)
    return "".join(letters)

# =========================
# ØªÙ†Ø¸ÙŠÙ Ø§Ø³Ù… Ø§Ù„Ø³ÙˆØ±Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
# =========================
def clean_surah_name(name):
    name = re.sub(r'^\d+[_-]*', '', name)
    name = re.sub(r'\.xlsx$', '', name)
    return name.strip()

# =========================
# Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„ÙØ§Øª Ø§Ù„Ø³ÙˆØ± Ù…Ù† Ù…Ø¬Ù„Ø¯ data
# =========================
@st.cache_data
def get_surah_files():
    files = {}
    files[0] = {"name": "Ø§Ù„Ù‚Ø±Ø¢Ù† ÙƒÙ„Ù‡", "path": None}
    for file in os.listdir("data"):
        if file.endswith(".xlsx"):
            match = re.match(r"^(\d+)", file)
            surah_num = int(match.group(1)) if match else 999
            surah_name = clean_surah_name(file.replace(".xlsx", ""))
            files[surah_num] = {"name": surah_name, "path": os.path.join("data", file)}
    return dict(sorted(files.items(), key=lambda x: x[0]))

surah_files_dict = get_surah_files()
surah_options = [v["name"] for v in surah_files_dict.values()]
selected_surah = st.sidebar.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ø³ÙˆØ±Ø©", surah_options)

# Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù Ø­Ø³Ø¨ Ø§Ø³Ù… Ø§Ù„Ø³ÙˆØ±Ø©
def get_file_path_by_name(surah_name):
    for v in surah_files_dict.values():
        if v["name"] == surah_name:
            return v["path"]
    return None

# =========================
# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¯Ø§ØªØ§ Ø­Ø³Ø¨ Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±
# =========================
@st.cache_data
def load_data(selected_surah_name):
    if selected_surah_name == "Ø§Ù„Ù‚Ø±Ø¢Ù† ÙƒÙ„Ù‡":
        all_rows = []
        for k, v in surah_files_dict.items():
            if v["path"] is None:
                continue
            df_temp = pd.read_excel(v["path"])
            file_num_match = re.match(r"^(\d+)", os.path.basename(v["path"]))
            surah_id = int(file_num_match.group(1)) if file_num_match else 999
            df_temp["surah_id"] = surah_id
            df_temp["surah_name"] = clean_surah_name(v["name"])
            all_rows.append(df_temp)
        df_all = pd.concat(all_rows, ignore_index=True).sort_values(["surah_id", "ayah_number"]).reset_index(drop=True)
        return df_all
    else:
        path = get_file_path_by_name(selected_surah_name)
        df_single = pd.read_excel(path)
        file_num_match = re.match(r"^(\d+)", os.path.basename(path))
        surah_id = int(file_num_match.group(1)) if file_num_match else 999
        df_single["surah_id"] = surah_id
        df_single["surah_name"] = clean_surah_name(selected_surah_name)
        return df_single.sort_values("ayah_number").reset_index(drop=True)

df = load_data(selected_surah)

# =========================
# Ø¥Ø­ØµØ§Ø¡Ø§Øª Ø§Ù„Ø³ÙˆØ± ÙˆØ§Ù„Ø¢ÙŠØ§Øª
# =========================
st.markdown("## ğŸ“Š Ø¥Ø­ØµØ§Ø¡Ø§Øª")

if selected_surah == "Ø§Ù„Ù‚Ø±Ø¢Ù† ÙƒÙ„Ù‡":
    surah_order = df[["surah_id", "surah_name"]].drop_duplicates().sort_values("surah_id").copy()
    surah_order["surah_name"] = surah_order["surah_name"].apply(clean_surah_name)
    stats_df = (
    df.groupby(["surah_id", "surah_name"])["ayah_number"]
    .max()   #<<<< Ø¨Ø¯Ù„ nunique
    .reset_index()
    .rename(columns={"surah_id":"Ø±Ù‚Ù… Ø§Ù„Ø³ÙˆØ±Ø©","surah_name":"Ø§Ø³Ù… Ø§Ù„Ø³ÙˆØ±Ø©","ayah_number":"Ø¹Ø¯Ø¯ Ø§Ù„Ø¢ÙŠØ§Øª"})
)

    stats_df = stats_df if 'stats_df' in locals() else None
    total_ayahs = stats_df["Ø¹Ø¯Ø¯ Ø§Ù„Ø¢ÙŠØ§Øª"].sum()
    st.markdown(f"""
        <div style="background-color:black; padding:15px; border-radius:10px; text-align:center;">
            <h3>ğŸ“– Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¹Ø¯Ø¯ Ø¢ÙŠØ§Øª Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ…</h3>
            <h1 style="color:white;">{total_ayahs}</h1>
        </div>""", unsafe_allow_html=True)
    st.divider()
    st.markdown("### ğŸ“˜ Ø¹Ø¯Ø¯ Ø§Ù„Ø¢ÙŠØ§Øª ÙÙŠ ÙƒÙ„ Ø³ÙˆØ±Ø© Ø¨ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…ØµØ­Ù")
    
    # =========================
    # Ø¬Ø¯ÙˆÙ„ Ø¥Ø­ØµØ§Ø¡Ø§Øª Ø¨Ø¥Ø·Ø§Ø± Ø°Ù‡Ø¨ÙŠ
    # =========================
    def render_gold_table_scroll(df, max_rows_visible=15):
        # Ù†Ø­Ø³Ø¨ Ø§Ø±ØªÙØ§Ø¹ Ø§Ù„Ø­Ø§ÙˆÙŠØ© ØªÙ‚Ø±ÙŠØ¨Ø§: 40px Ù„ÙƒÙ„ ØµÙ + 45px Ù„Ù„Ø±Ø£Ø³
        container_height = max_rows_visible * 40 + 45
        return f"""
        <div style="overflow-x:auto; overflow-y:auto; max-height:{container_height}px; border:3px solid #CFA500; border-radius:10px; padding:5px;">
            {df.to_html(index=False, classes="gold-table", escape=False)}
        </div>
        """

    st.markdown("""
    <style>
    .gold-table {
        border-collapse: collapse;
        width: 100%;
        font-size: 18px;
        font-weight: bold;
    }
    .gold-table th, .gold-table td {
        border: 1px solid #CFA500;
        padding: 8px 12px;
        text-align: center;
    }
    .gold-table th {
        background-color: #fff7e6;
        color: #CFA500;
        font-size: 20px;
    }
    .gold-table tbody tr:hover {
        background-color: #fff3cc;
    }
    </style>
    """, unsafe_allow_html=True)

    # Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ù…Ø¹ Ø§Ù„ØªÙ…Ø±ÙŠØ±
    st.markdown(render_gold_table_scroll(stats_df, max_rows_visible=15), unsafe_allow_html=True)
# =========================
# Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ØµÙØ­Ø©
# =========================
st.markdown(f"""
    <div style="background-color:#f0f8ff; padding:15px; border-radius:10px;">
        <h1 style="color:#003366; text-align:center;">ğŸ“– Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ…</h1>
        <h3 style="color:#006699; text-align:center;">{clean_surah_name(selected_surah)}</h3>
    </div>""", unsafe_allow_html=True)
st.divider()

# =========================
# Ù†ÙˆØ¹ Ø§Ù„Ø¨Ø­Ø«
# =========================
search_type = st.radio("Ø§Ø®ØªØ± Ù†ÙˆØ¹ Ø§Ù„Ø¨Ø­Ø«", ["Ø¨Ø­Ø« Ø¨Ø±Ù‚Ù… Ø§Ù„Ø¢ÙŠØ©", "Ø¹Ø±Ø¶ Ø§Ù„Ø³ÙˆØ±Ø© ÙƒØ§Ù…Ù„Ø©", "Ø¨Ø­Ø« Ø­Ø±ÙˆÙ Ø§Ù„ÙƒÙ„Ù…Ø©","Ø¨Ø­Ø« Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø£ØµÙ„ÙŠØ©"], horizontal=True)
st.divider()

# =========================
# ØªØ¸Ù„ÙŠÙ„ Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù„Ø­Ø±ÙˆÙ
# =========================
def highlight_chars_as_input(text, keyword):
    keyword_clean = remove_tashkeel(keyword)
    highlighted = ""
    used = []
    for char in text:
        char_clean = remove_tashkeel(char)
        # ØªØ´ÙƒÙŠÙ„ â†’ Ø°Ù‡Ø¨ÙŠ
        if re.match(r'[\u0610-\u061A\u064B-\u065F\u0670\u06D6-\u06ED]', char):
            highlighted += f'<span style="color:#CFA500; font-weight:bold;">{char}</span>'
            continue
        # Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© â†’ Ø£Ø®Ø¶Ø± Ø¨ÙˆÙ„Ø¯ Ø£Ù‚ÙˆÙ‰
        if char_clean in keyword_clean and used.count(char_clean) < keyword_clean.count(char_clean):
            highlighted += f'<span style="color:green; font-weight:900;">{char}</span>'
            used.append(char_clean)
        else:
            # Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ù†Øµ â†’ Ø¨ÙˆÙ„Ø¯ Ø£Ù‚ÙˆÙ‰
            highlighted += f'<span style="font-weight:900;">{char}</span>'
    return highlighted

# =========================
# ğŸ” Ø¨Ø­Ø« Ø­Ø±ÙˆÙ Ø§Ù„ÙƒÙ„Ù…Ø©
# =========================
if search_type == "Ø¨Ø­Ø« Ø­Ø±ÙˆÙ Ø§Ù„ÙƒÙ„Ù…Ø©":
    keyword = st.text_input("Ø§ÙƒØªØ¨ Ø§Ù„Ø­Ø±ÙˆÙ Ù„Ù„Ø¨Ø­Ø« Ø¯Ø§Ø®Ù„ Ø§Ù„Ø¢ÙŠØ§Øª")
    if keyword:
        keyword_clean = remove_tashkeel(keyword)
        def contains_all_chars_counted(ayah):
            ayah_clean = remove_tashkeel(ayah)
            return all(ayah_clean.count(c) >= keyword_clean.count(c) for c in set(keyword_clean))
        results = df[df["ayah_text"].apply(contains_all_chars_counted)]
        if selected_surah == "Ø§Ù„Ù‚Ø±Ø¢Ù† ÙƒÙ„Ù‡":
            results = results.sort_values(["surah_id","ayah_number"]).reset_index(drop=True)
        st.write(f"Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬: {len(results)}")
        for _, row in results.iterrows():
            st.markdown(
                f"<b>{row['surah_name']} ({row['ayah_number']})</b><br>"
                f"{highlight_tashkeel(highlight_chars_as_input(row['ayah_text'], keyword))}<br><br>",
                unsafe_allow_html=True
            )

# =========================
# ğŸ”¢ Ø¨Ø­Ø« Ø¨Ø±Ù‚Ù… Ø§Ù„Ø¢ÙŠØ©
# =========================
elif search_type == "Ø¨Ø­Ø« Ø¨Ø±Ù‚Ù… Ø§Ù„Ø¢ÙŠØ©":
    ayah_number = st.number_input("Ø£Ø¯Ø®Ù„ Ø±Ù‚Ù… Ø§Ù„Ø¢ÙŠØ©", min_value=1, max_value=int(df["ayah_number"].max()), step=1)
    result = df[df["ayah_number"] == ayah_number]
    for _, row in result.iterrows():
        ayah_html = highlight_tashkeel(highlight_chars_as_input(row['ayah_text'], keyword)) if 'keyword' in locals() and keyword else highlight_tashkeel(row['ayah_text'])
        st.markdown(
            f"<b>{row['surah_name']} ({row['ayah_number']})</b><br>"
            f"{ayah_html}<br><br>",
            unsafe_allow_html=True
        )

# =========================
# ğŸ“– Ø¹Ø±Ø¶ Ø§Ù„Ø³ÙˆØ±Ø© ÙƒØ§Ù…Ù„Ø©
# =========================
elif search_type == "Ø¹Ø±Ø¶ Ø§Ù„Ø³ÙˆØ±Ø© ÙƒØ§Ù…Ù„Ø©":
    for _, row in df.iterrows():
        st.markdown(
            f"<b>{row['surah_name']} ({row['ayah_number']})</b><br>"
            f"{highlight_tashkeel(row['ayah_text'])}<br><br>",
            unsafe_allow_html=True
        )

# =========================
# â­ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¬Ø¯ÙŠØ¯: Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø£ØµÙ„ÙŠØ© â­
# =========================
# =========================
# â­ Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø£ØµÙ„ÙŠØ© â­
# =========================
elif search_type == "Ø¨Ø­Ø« Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø£ØµÙ„ÙŠØ©":

    st.markdown("### ğŸ”  Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø£ØµÙ„ÙŠØ© (Ø¨Ø¯ÙˆÙ† ØªÙƒØ±Ø§Ø± â€“ Ø¨Ø¯ÙˆÙ† Ù‡Ù…Ø²Ø§Øª â€“ Ø¨Ø¯ÙˆÙ† Ù…Ø³Ø§ÙØ§Øª)")
    search_letters = st.text_input("Ø§ÙƒØªØ¨ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø£ØµÙ„ÙŠØ© Ù„Ù„Ø¨Ø­Ø«", placeholder="Ù…Ø«Ù„: Ø§Ù„Ù…  | ÙƒÙ‡Ø¹Øµ  | ÙŠØ³  | Ø·Ø³Ù…")

    # -------------------------
    # ÙÙŠ Ø­Ø§Ù„Ø© Ø¹Ø¯Ù… ÙƒØªØ§Ø¨Ø© Ø£ÙŠ Ø´ÙŠØ¡ â†’ Ø¹Ø±Ø¶ Ø§Ù„Ù…ØµØ­Ù ÙƒØ§Ù…Ù„
    # -------------------------
    if not search_letters:
        st.markdown("#### ğŸ“– Ø¹Ø±Ø¶ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø£ØµÙ„ÙŠØ© Ù„ÙƒÙ„ Ø¢ÙŠØ© (Ø¨Ø¯ÙˆÙ† Ø¨Ø­Ø«)")
        for _, row in df.iterrows():
            ayah_letters = extract_original_letters(row["ayah_text"])
            st.markdown(f"""
                <b>{row['surah_name']} ({row['ayah_number']})</b><br>
                <span style="font-size:22px; color:green; font-weight:bold;">{ayah_letters}</span><br>
            """, unsafe_allow_html=True)
        st.stop()  # Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ÙƒÙˆØ¯ Ù‡Ù†Ø§ Ø­ØªÙ‰ Ù„Ø§ ÙŠÙ†ÙØ° Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„ØªØ§Ù„ÙŠ

    # -------------------------
    # Ø¹Ù†Ø¯ ÙˆØ¬ÙˆØ¯ Ø¨Ø­Ø« â†’ Ù†ÙØ° Ø§Ù„ØªØµÙÙŠØ© ÙÙ‚Ø·
    # -------------------------
    user_letters = normalize_hamza_to_alif(remove_tashkeel(search_letters))
    user_letters = re.sub(r'[^Ø§-ÙŠ]', '', user_letters)  # Ø­Ø°Ù Ø£ÙŠ Ø´ÙŠØ¡ ØºÙŠØ± Ø§Ù„Ø­Ø±ÙˆÙ
    user_unique = "".join(sorted(set(user_letters)))    # ØªØ±ØªÙŠØ¨ ÙˆØªÙØ±ÙŠØ¯

    st.markdown(f"### Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ù…Ø¹ØªÙ…Ø¯Ø© ÙÙŠ Ø§Ù„Ø¨Ø­Ø«: **{user_unique}**")
    st.markdown("---")

    results = []
    for _, row in df.iterrows():
        ayah_letters = extract_original_letters(row["ayah_text"])
        ayah_unique = "".join(sorted(set(normalize_hamza_to_alif(ayah_letters))))

        if ayah_unique == user_unique:
            results.append(row)

    # -------------------------
    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¨Ø¯ÙˆÙ† ØªÙƒØ±Ø§Ø±
    # -------------------------

    for r in results:
        lets = extract_original_letters(r['ayah_text'])
        st.markdown(f"""
            <b>{r['surah_name']} ({r['ayah_number']})</b><br>
            <span style="font-size:22px; color:green; font-weight:bold;">{lets}</span><br>
            <i>{r['ayah_text']}</i>
            <hr>
        """, unsafe_allow_html=True)


try:
    footer_img = Image.open("assets/footer.png")
    st.image(footer_img, use_container_width=False)
except:
    st.warning("âš  Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ØµÙˆØ±Ø© footer.png Ø¯Ø§Ø®Ù„ Ù…Ø¬Ù„Ø¯ assets")
